\documentclass[a4paper]{article}
%% Formatting %%
\usepackage[margin=3cm]{geometry}
\usepackage{type1cm, titlesec, fancyhdr, titling}
\usepackage{multicol}
\usepackage[dvipsnames]{xcolor}
\usepackage{ulem}
\usepackage{parskip}
\setlength{\parindent}{2em}
\setlength{\headheight}{15pt}
\setlength{\droptitle}{-1.5cm}
\parindent=24pt
%% Math and Symbols %%
\usepackage{amsmath,amsthm,amssymb, mathtools}
\usepackage{yhmath, faktor, dsfont}
\usepackage{academicons, wasysym, marvosym}
\usepackage[scr]{rsfso} 
\usepackage{latexsym, amsmath, amscd, amsmath, amsthm}
\usepackage{amssymb,amsmath,amsthm,graphicx,dsfont}
\usepackage{hyperref}

%% Enhancement %%
\usepackage{graphicx, tabularx}
\usepackage[shortlabels,inline]{enumitem}
%% TikZ %%
\usepackage{tikz-cd}
\usepackage[breakable]{tcolorbox}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{calc, arrows,matrix}

%% Other packages %%
\usepackage{amsopn}

%% Traditional Chinese %%
\usepackage{CJKutf8}

%% Math environments %%
\newtheoremstyle{mystyle}
  {6pt}{15pt}% 上下間距
  {}%          內文字體
  {}%              縮排
  {\bf}%       標頭字體
  {.}%       標頭後標點
  {1em}% 內文與標頭距離
  {}% Theorem head spec (can be left empty, meaning 'normal')
\theoremstyle{mystyle}	
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem*{exercise}{Exercise}
\newtheorem*{solution}{Solution}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{property}[theorem]{Property}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{problem}{Problem}
\newtheorem{answer}{Answer}[section]
\newtheorem{fact}[theorem]{Fact}
\newtheorem*{recall}{Recall}
\newtheorem*{remark}{Remark}
\newtheorem*{claim}{Claim}
\newtheorem*{observation}{Observation}

\begin{document}
\begin{CJK}{UTF8}{bkai}

    \title{%
  \textbf{The Design and Analysis of Algorithms} \\
  \vspace{0.5cm}
  \large Selected Solutions to Exercises in Introduction to Algorithms (4th Edition)
}
\author{黃紹凱 Jonathan Huang}
\date{\today}

\maketitle

\section{Chapter 3}

%
\begin{exercise}[3-3]
\textbf{Ordering by asymptotic growth rates.}
    ~
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item Rank the following functions by order of growth. That is, find an arrangement $g_1, g_2, \dots, g_{30}$ of the functions satisfying $g_1 = \Omega(g_2)$, $g_2 = \Omega(g_3)$, $\dots$, $g_{29} = \Omega(g_{30})$. Partition your list into equivalence classes such that functions $f(n)$ and $g(n)$ belong to the same class if and only if $f(n) = \Theta(g(n))$.
        \[
        \lg(\lg^* n),\quad 2^{\lg^* n},\quad (\sqrt{2})^{\lg n},\quad n^2,\quad n!,\quad (\lg n)!,\quad (3/2)^n,\quad n^3,\quad \lg^2 n,\quad \lg(n!),\quad 2^{2^n},\quad n^{1/\lg n},
        \]
        \[
        \ln\ln n,\quad \lg^* n,\quad n\cdot 2^n,\quad n^{\lg\lg n},\quad \ln n,\quad 1,\quad 2^{\lg n},\quad (\lg n)^{\lg n},\quad e^n,\quad 4^{\lg n},\quad (n+1)!,\quad \sqrt{\lg n},
        \]
        \[
        \lg^*(\lg n),\quad 2^{\sqrt{2\lg n}},\quad n,\quad 2^n,\quad n\lg n,\quad 2^{2^{n+1}}.
        \]
        \item Give an example of a single nonnegative function $f(n)$ such that for all functions $g_i(n)$ in part (a), $f(n)$ is neither $O(g_i(n))$ nor $\Omega(g_i(n))$.
    \end{enumerate}
\end{exercise}

\begin{solution}
    ~
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item The iterated logarithm $ \lg^* n $ belong to the class $ \Theta(\lg^* n) $, which grows extremely slow. Also, notice that $ \lg(\lg^* n) = O \left(\lg^* (\lg n)\right) $, since $ \lg^* (\lg n) = \lg^* n - 1 $. Thus, we have the following ordering:
        \begin{enumerate}
            \item $ 1 $
            \item $ \lg(\lg^* n) $, $ \lg^* (\lg n) $ 
            \item $ \lg^* n $
            \item $ \ln\ln n $
            \item $ \sqrt{\lg n} $
            \item $ \lg(n!) $, $ \lg^2 n $
        \end{enumerate}
        \item An example of such a function is
        \[
            f(n) = \begin{cases}
                n^{1/2}, & \text{if $n$ is even}, \\
                n^{3/2}, & \text{if $n$ is odd}.
            \end{cases}
        \]
        This function oscillates between two different growth rates depending on the parity of $n$, thus it is not comparable to any of the functions in part (a).
    \end{enumerate}
\end{solution}

%
\begin{exercise}[3-4]
    \textbf{Asymptotic notation properties.}

    Let $f(n)$ and $g(n)$ be asymptotically positive functions. Prove or disprove each of the following conjectures:
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item $f(n) = O(g(n))$ implies $g(n) = O(f(n))$.
        \item $f(n) + g(n) = \Theta(\min\{f(n), g(n)\})$.
        \item $f(n) = O(g(n))$ implies $\lg f(n) = O(\lg g(n))$, where $\lg g(n) \ge 1$ and $f(n) \ge 1$ for all sufficiently large $n$.
        \item $f(n) = O(g(n))$ implies $2^{f(n)} = O(2^{g(n)})$.
        \item $f(n) = O((f(n))^2)$.
        \item $f(n) = O(g(n))$ implies $g(n) = \Omega(f(n))$.
        \item $f(n) = \Theta(f(n/2))$.
        \item $f(n) + o(f(n)) = \Theta(f(n))$.
    \end{enumerate}
\end{exercise}

\section{Chapter 4}

%
\begin{exercise}[4.2-6]
    Suppose that you have a $\Theta(n^\alpha)$-time algorithm for squaring $n \times n$ matrices, where $\alpha \ge 2$. Show how to use that algorithm to multiply two different $n \times n$ matrices in $\Theta(n^\alpha)$ time.
\end{exercise}

\begin{solution}
    Given $ A, B \in M_n (\mathbb{R}) $, construct the block matrix 
    \[
        C = \begin{pmatrix}
            A & B \\ O & O \\
        \end{pmatrix} \in M_{2n} (\mathbb{R}) \;\Longrightarrow\; C^2 = \begin{pmatrix}
            A^2 & AB \\ O & O
        \end{pmatrix},
    \] 
    by applying the $ \Theta (n^\alpha) $ algorithm to $ C $. Then, output the top-right $ n \times n $ block matrix. The time complexity is $ \Theta ((2n)^\alpha) = \Theta (n^\alpha) $.
\end{solution}

%
\begin{exercise}[4.3-1]
    Use the substitution method to show that each of the following recurrences defined on the reals has the asymptotic solution specified:
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item $T(n) = T(n - 1) + n$ has solution $T(n) = O(n^2)$.
        \item $T(n) = T(n/2) + \Theta(1)$ has solution $T(n) = O(\lg n)$.
        \item $T(n) = 2T(n/2) + n$ has solution $T(n) = \Theta(n \lg n)$.
        \item $T(n) = 2T(n/2 + 17) + n$ has solution $T(n) = O(n \lg n)$.
        \item $T(n) = 2T(n/3) + \Theta(n)$ has solution $T(n) = \Theta(n)$.
        \item $T(n) = 4T(n/2) + \Theta(n)$ has solution $T(n) = \Theta(n^2)$.
    \end{enumerate}
\end{exercise}

\begin{solution}
    ~
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item 
    \end{enumerate}
\end{solution}

%
\begin{exercise}[4.4-4]
    Use a recursion tree to justify a good guess for the solution to the recurrence 
    \[
    T(n) = T(\alpha n) + T((1-\alpha)n) + \Theta(n),
    \]
    where $\alpha$ is a constant in the range $0 < \alpha < 1$.
\end{exercise}

\begin{solution}
    
\end{solution}

%
\begin{exercise}[4.5-1]
    Use the master method to give tight asymptotic bounds for the following recurrences:
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item $T(n) = 2T(n/4) + 1$.
        \item $T(n) = 2T(n/4) + \sqrt{n}$.
        \item $T(n) = 2T(n/4) + \sqrt{n} \lg^2 n$.
        \item $T(n) = 2T(n/4) + n$.
        \item $T(n) = 2T(n/4) + n^2$.
    \end{enumerate}
\end{exercise}

\begin{solution}
    ~
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item 
    \end{enumerate}
\end{solution}

%
\begin{exercise}[Problem 4-4]
Give asymptotically tight upper and lower bounds for $T(n)$ in each of the following recurrences. Justify your answers.
\begin{enumerate}[label=\textbf{\alph*.}]
    \item $T(n) = 5T(n/3) + n \lg n$.
    \item $T(n) = 3T(n/3) + n/\lg n$.
    \item $T(n) = 8T(n/2) + n^3 \sqrt{n}$.
    \item $T(n) = 2T(n/2 - 2) + n/2$.
    \item $T(n) = 2T(n/2) + n/\lg n$.
    \item $T(n) = T(n/2) + T(n/4) + T(n/8) + n$.
    \item $T(n) = T(n-1) + 1/n$.
    \item $T(n) = T(n-1) + \lg n$.
    \item $T(n) = T(n-2) + 1/\lg n$.
    \item $T(n) = \sqrt{n}\, T(\sqrt{n}) + n$.
\end{enumerate}
\end{exercise}

\begin{solution}
    ~
    \begin{enumerate}[label=\textbf{\alph*.}]
        \item 
    \end{enumerate}
\end{solution}

\section{Chapter 6}

% 
\begin{exercise}[6.1-8]
    Show that, with the array representation for storing an $n$-element heap, the leaves are the nodes indexed by $\lfloor n/2 \rfloor + 1, \lfloor n/2 \rfloor + 2, \dots, n$.
\end{exercise}

%
\begin{exercise}[6.3-4]
    Show that there are at most $\left\lceil \frac{n}{2^{h+1}} \right\rceil$ nodes of height $h$ in any $n$-element heap.
\end{exercise}

%
\begin{exercise}[6-1]
    \textbf{Building a heap using insertion.}

    One way to build a heap is by repeatedly calling \textsc{MAX-HEAP-INSERT} to insert the elements into the heap. Consider the procedure \textsc{BUILD-MAX-HEAP'}.

    \begin{center}
    \begin{tabular}{|l|}
    \hline
    \textsc{BUILD-MAX-HEAP'}$(A, n)$ \\
    \hspace{1em}1.\quad $A.\text{heap-size} = 1$ \\
    \hspace{1em}2.\quad \textbf{for} $i = 2$ \textbf{to} $n$ \\
    \hspace{2em}3.\quad \textsc{MAX-HEAP-INSERT}$(A, A[i], n)$ \\
    \hline
    \end{tabular}
    \end{center}

    \begin{enumerate}[label=\textbf{\alph*.}]
        \item Do the procedures \textsc{BUILD-MAX-HEAP} and \textsc{BUILD-MAX-HEAP'} always create the same heap when run on the same input array? Prove that they do, or provide a counterexample.
        \item Show that in the worst case, \textsc{BUILD-MAX-HEAP'} requires $\Theta(n \lg n)$ time to build an $n$-element heap.
    \end{enumerate}
\end{exercise}

\section{Chapter 7}

% 
\begin{exercise}[7.2-5]
    Suppose that the splits at every level of quicksort are in the constant proportion $\alpha$ to $\beta$, where $\alpha + \beta = 1$ and $0 < \alpha \le \beta < 1$. Show that the minimum depth of a leaf in the recursion tree is approximately $\log_{1/\alpha} n$ and that the maximum depth is approximately $\log_{1/\beta} n$. (Don't worry about integer round-off.)
\end{exercise}

%
\begin{exercise}[7.3-2]
    When \textsc{RANDOMIZED-QUICKSORT} runs, how many calls are made to the random-number generator \textsc{RANDOM} in the worst case? How about in the best case? Give your answer in terms of $\Theta$-notation.
\end{exercise}

%
\begin{exercise}[7.4-4]
    Show that \textsc{RANDOMIZED-QUICKSORT}'s expected running time is $\Omega(n \lg n)$.
\end{exercise}

%
\begin{problem}[7-4]
Professors Howard, Fine, and Howard have proposed a deceptively simple sorting algorithm, named \textsc{STOOGE-SORT} in their honor.

\begin{enumerate}[label=(\alph*)]
  \item Argue that the call \textsc{STOOGE-SORT}$(A, 1, n)$ correctly sorts the array $A[1 : n]$.
  \item Give a recurrence for the worst-case running time of \textsc{STOOGE-SORT} and a tight asymptotic ($\Theta$-notation) bound on the worst-case running time.
  \item Compare the worst-case running time of \textsc{STOOGE-SORT} with that of insertion sort, merge sort, heapsort, and quicksort. Do the professors deserve tenure?
\end{enumerate}
\end{problem}

\section{Chapter 8}

%
\begin{exercise}[8.2-6]
    Describe an algorithm that, given $n$ integers in the range $0$ to $k$, preprocesses its input and then answers any query about how many of the $n$ integers fall into a range $[a : b]$ in $O(1)$ time. Your algorithm should use $\Theta(n + k)$ preprocessing time.
\end{exercise}

%
\begin{exercise}[8.3-5]
    Show how to sort $n$ integers in the range $0$ to $n^3 - 1$ in $O(n)$ time.
\end{exercise}

%
\begin{exercise}[8.4-2]
    Explain why the worst-case running time for bucket sort is $\Theta(n^2)$. What simple change to the algorithm preserves its linear average-case running time and makes its worst-case running time $O(n \lg n)$?
\end{exercise}

%
\begin{problem}[8-2]
    You have an array of $n$ data records to sort, each with a key of $0$ or $1$. An algorithm for sorting such a set of records might possess some subset of the following three desirable characteristics:

    \begin{enumerate}
        \item The algorithm runs in $O(n)$ time.
        \item The algorithm is stable.
        \item The algorithm sorts in place, using no more than a constant amount of storage space in addition to the original array.
    \end{enumerate}

    \begin{enumerate}[label=(\alph*)]
        \item Give an algorithm that satisfies criteria 1 and 2 above.
        \item Give an algorithm that satisfies criteria 1 and 3 above.
        \item Give an algorithm that satisfies criteria 2 and 3 above.
        \item Can you use any of your sorting algorithms from parts (a)–(c) as the sorting method used in line 2 of \textsc{RADIX-SORT}, so that \textsc{RADIX-SORT} sorts $n$ records with $b$-bit keys in $O(bn)$ time? Explain how or why not.
        \item Suppose that the $n$ records have keys in the range from $1$ to $k$. Show how to modify counting sort so that it sorts the records in place in $O(n + k)$ time. You may use $O(k)$ storage outside the input array. Is your algorithm stable?
    \end{enumerate}
\end{problem}

\end{CJK}
\end{document}